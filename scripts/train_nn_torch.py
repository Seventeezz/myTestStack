import os
import numpy as np
import torch
from torch.utils.data import Dataset
import torch.nn.functional as F
from torch.utils.data import DataLoader, random_split
import sys
import argparse

from Game.card_tools import card_tools
from NeuralNetwork.value_nn_torch import ValueNn
os.chdir('..')
sys.path.append( os.path.join(os.getcwd(),'src') )

STREET_TO_PHASE = {
    1: 'preflop',
    2: 'flop',
    3: 'turn',
    4: 'river'
}


def basic_huber_loss(y_true, y_pred, delta=1.0):
    return F.huber_loss(y_pred, y_true, delta=delta)

def masked_huber_loss(y_true, y_pred, delta=1.0):
    mask = (y_true != 0).float()
    num_active = mask.sum()
    base_loss = F.huber_loss(y_pred, y_true, delta=delta, reduction='none')
    masked_loss = base_loss * mask
    multiplier = y_true.numel() / (num_active + 1e-6)  # é˜²æ­¢é™¤0
    return masked_loss.mean() * multiplier

# å®šä¹‰æ•°æ®Dataset
class PokerDataset(Dataset):
    def __init__(self, npy_dir):
        self.input_paths = sorted([os.path.join(npy_dir, f) for f in os.listdir(npy_dir) if f.startswith("inputs")])
        self.target_paths = sorted([os.path.join(npy_dir, f) for f in os.listdir(npy_dir) if f.startswith("targets")])
        self.board_paths = sorted([os.path.join(npy_dir, f) for f in os.listdir(npy_dir) if f.startswith("boards")])

        assert len(self.input_paths) == len(self.target_paths) == len(self.board_paths)

        # é¢„åŠ è½½æ‰€æœ‰æ•°æ®
        self.inputs = [np.load(p) for p in self.input_paths]
        self.targets = [np.load(p) for p in self.target_paths]
        self.boards = [np.load(p) for p in self.board_paths]

        self.data = []  # (x, y, board) çš„æ‰å¹³åŒ–åˆ—è¡¨
        for x_batch, y_batch, board_batch in zip(self.inputs, self.targets, self.boards):
            # è®¡ç®—æ¯ä¸ªboardå¯¹åº”çš„x_batché‡å¤æ¬¡æ•°ï¼Œä¿è¯å¯¹é½
            batch_size = len(x_batch) // len(board_batch)
            # board æ‰©å±•æˆå’Œ x_batch å¯¹é½çš„å½¢çŠ¶
            extended_boards = np.repeat(board_batch, batch_size, axis=0)  # [batch_size * num_boards, board_size]

            assert len(x_batch) == len(y_batch) == len(extended_boards), \
                f"Data length mismatch: {len(x_batch)}, {len(y_batch)}, {len(extended_boards)}"

            for i in range(len(x_batch)):
                self.data.append((x_batch[i], y_batch[i], extended_boards[i]))

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        x, y, board = self.data[idx]
        # 1. ä½¿ç”¨å’ŒTFRecordsConverterå®Œå…¨ä¸€è‡´çš„boardè½¬ç‰¹å¾æ–¹æ³•
        b = card_tools.convert_board_to_nn_feature(board)
        # 2. æ‹¼æ¥ x å’Œ bï¼ˆboardçš„ç‰¹å¾ï¼‰
        nn_input = np.zeros(len(x) + len(b), dtype=np.float32)
        nn_input[:len(x)] = x
        nn_input[len(x):] = b
        # 3. maskå¤„ç†targetsï¼Œå‚è€ƒTFRecordsConverterä¸­çš„é€»è¾‘
        ranges = x[:-1]  # å¿½ç•¥æœ€åä¸€ä¸ªpotçš„å€¼
        mask = np.ones_like(ranges, dtype=np.float32)
        mask[ranges == 0] = 0
        nn_target = y * mask
        return torch.tensor(nn_input, dtype=torch.float32), torch.tensor(nn_target, dtype=torch.float32)

    def convert_board_to_nn_feature(self, board):
        # è¿™é‡Œç›´æ¥è¿”å›float32ç±»å‹boardç‰¹å¾ï¼Œå¦‚æœä½ æœ‰card_toolsé‡Œæ›´å¤æ‚çš„è½¬æ¢ï¼Œå¯ä»¥æ›¿æ¢æ­¤å¤„
        return board.astype(np.float32)


# === è®­ç»ƒå‡½æ•° ===
def train_one_epoch(model, loader, optimizer):
    model.train()
    total_loss = 0
    for inputs, targets in loader:
        inputs = inputs.to(model.device)
        targets = targets.to(model.device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = masked_huber_loss(targets, outputs)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    return total_loss / len(loader)


# === éªŒè¯å‡½æ•° ===
def evaluate(model, loader):
    model.eval()
    total_loss = 0
    with torch.no_grad():
        for inputs, targets in loader:
            inputs = inputs.to(model.device)
            targets = targets.to(model.device)
            outputs = model(inputs)
            loss = masked_huber_loss(targets, outputs)
            total_loss += loss.item()
    return total_loss / len(loader)


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--street', type=int, default=2, help='è®¾ç½®å½“å‰è®­ç»ƒçš„streetå€¼ï¼ˆ1: preflop, 2: flop, 3: turn, 4: riverï¼‰')
    parser.add_argument('--train_type', type=str, default='root_nodes', choices=['root_nodes', 'leaf_nodes'], help='è®­ç»ƒç±»å‹')
    args = parser.parse_args()

    STREET = args.street
    TRAIN_TYPE = args.train_type

    # ä¸‹é¢çš„ CFG ä¹Ÿè¦ç”¨æ–°çš„ STREET å’Œ TRAIN_TYPE
    CFG = {
        'n_epochs': 100,
        'batch_size': 64,
        'learning_rate': 1e-4,
        'n_workers': 0,
        'model_save_path': f'./data/Models/{STREET_TO_PHASE[STREET]}/weights.{TRAIN_TYPE}.pt',
        "data_path": f"./data/TrainSamples/{STREET_TO_PHASE[STREET]}/{TRAIN_TYPE}_npy",
    }

    dataset = PokerDataset(CFG['data_path'])
    val_size = int(0.1 * len(dataset))
    train_size = len(dataset) - val_size
    train_set, val_set = random_split(dataset, [train_size, val_size])

    train_loader = DataLoader(train_set, batch_size=CFG['batch_size'], shuffle=True, num_workers=CFG['n_workers'])
    val_loader = DataLoader(val_set, batch_size=CFG['batch_size'], shuffle=False, num_workers=CFG['n_workers'])

    # === åˆå§‹åŒ–æ¨¡å‹ ===
    model = ValueNn(
        street=STREET,  # æ›¿æ¢æˆä½ è®­ç»ƒçš„ street å€¼ï¼ˆ0,1,2,3ï¼‰
        pretrained_weights=False,
        approximate='root_nodes',
        trainning_mode=True
    )
    optimizer = torch.optim.Adam(model.parameters(), lr=CFG['learning_rate'])

    # === ä¸»è®­ç»ƒå¾ªç¯ ===
    best_val_loss = float('inf')

    for epoch in range(CFG["n_epochs"]):
        train_loss = train_one_epoch(model, train_loader, optimizer)
        val_loss = evaluate(model, val_loader)

        print(f"[Epoch {epoch + 1}/{CFG['n_epochs']}] Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f}")
        # ä¿å­˜æœ€ä¼˜æ¨¡å‹
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            torch.save(model.state_dict(), CFG["model_save_path"])
            print(f"âœ… Saved new best model at {CFG['model_save_path']}")

    print("ğŸ‰ Training complete.")